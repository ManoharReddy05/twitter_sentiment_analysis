{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISxhUK66YsSE",
        "outputId": "16bf5361-4280-4e41-cbab-4b87b69e380b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 5 scores: [0.34342466 0.27346501 0.59303341 0.2951069  0.61087559]\n",
            "accuracy (train data): 0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def import_tweets(filename, header=None):\n",
        "    tweet_dataset = pd.read_csv(filename, encoding='utf', header=header,engine='python',on_bad_lines = 'skip')\n",
        "    tweet_dataset.columns = ['sentiment', 'id', 'date', 'flag', 'user', 'text']\n",
        "    for i in ['flag', 'id', 'user', 'date']:\n",
        "        del tweet_dataset[i]\n",
        "    tweet_dataset.sentiment = tweet_dataset.sentiment.replace(4, 1)\n",
        "    return tweet_dataset\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet)\n",
        "    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet)\n",
        "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
        "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
        "    return tweet\n",
        "\n",
        "def feature_extraction(data, method=\"tfidf\"):\n",
        "    if method == \"tfidf\":\n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        tfv = TfidfVectorizer(sublinear_tf=True, stop_words=\"english\")\n",
        "        features = tfv.fit_transform(data)\n",
        "    elif method == \"doc2vec\":\n",
        "        features = None\n",
        "    else:\n",
        "        return \"Incorrect inputs\"\n",
        "    return features\n",
        "\n",
        "def train_classifier(features, label, classifier=\"logistic_regression\"):\n",
        "    from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "    if classifier == \"logistic_regression\":\n",
        "        from sklearn.linear_model import LogisticRegression\n",
        "        model = LogisticRegression(C=1.)\n",
        "    elif classifier == \"naive_bayes\":\n",
        "        from sklearn.naive_bayes import MultinomialNB\n",
        "        model = MultinomialNB()\n",
        "    elif classifier == \"svm\":\n",
        "        from sklearn.svm import SVC\n",
        "        model = SVC(probability=True)\n",
        "    else:\n",
        "        print(\"Incorrect selection of classifier\")\n",
        "        return\n",
        "\n",
        "    model.fit(features, label)\n",
        "    probability_to_be_positive = model.predict_proba(features)[:, 1]\n",
        "    predicted_labels = model.predict(features)\n",
        "    accuracy = accuracy_score(label, predicted_labels)\n",
        "\n",
        "    print(\"top 5 scores:\", probability_to_be_positive[:5])\n",
        "    print(\"accuracy (train data):\", accuracy)\n",
        "\n",
        "tweet_dataset = import_tweets(\"/content/dummy_tweets.csv\")\n",
        "tweet_dataset['text'] = tweet_dataset['text'].apply(preprocess_tweet)\n",
        "data = np.array(tweet_dataset.text)\n",
        "label = np.array(tweet_dataset.sentiment)\n",
        "features = feature_extraction(data, method=\"tfidf\")\n",
        "train_classifier(features, label, \"logistic_regression\")\n"
      ]
    }
  ]
}